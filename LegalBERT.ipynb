{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"datasets\" \"scikit-learn\" \"torchmetrics>=0.7\" \"scipy\" \"pytorch-lightning>=1.4\" \"transformers\" \"torchtext>=0.9\" \"setuptools==59.5.0\" \"ipython[notebook]\" \"torch>=1.8\" \"seaborn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LiU/732A81 - Text Mining project\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "%cd LiU/732A81 - Text Mining project\n",
    "%pwd\n",
    "\n",
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Huggingface transformers\n",
    "import transformers\n",
    "from transformers import BertModel,BertTokenizer,AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "#handling html data\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: eurlex/eurlex57k\n",
      "Found cached dataset eurlex (/root/.cache/huggingface/datasets/eurlex/eurlex57k/1.1.0/d2fdeaa4fcb5f41394d2ed0317c8541d7f9be85d2d601b9fa586c8b461bc3a34)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f365cca4547c47a9915e6d056751bc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('eurlex')\n",
    "#eurovoc_concepts_df = pd.read_json('./data/datasets/EURLEX57K/eurovoc_concepts.jsonl', lines=True)\n",
    "\n",
    "train = pd.DataFrame(dataset['train'])\n",
    "test = pd.DataFrame(dataset['test'])\n",
    "val = pd.DataFrame(dataset['validation'])\n",
    "#cumulative = pd.concat([train, test, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from disk\n",
    "import pickle\n",
    "with open('./data/preprocessed/x_train.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with open('./data/preprocessed/x_test.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "with open('./data/preprocessed/x_val.pkl', 'rb') as f:\n",
    "    x_val = pickle.load(f)\n",
    "with open('./data/preprocessed/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('./data/preprocessed/y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "with open('./data/preprocessed/y_val.pkl', 'rb') as f:\n",
    "    y_val = pickle.load(f)\n",
    "with open('./data/preprocessed/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "with open('./data/preprocessed/eurovoc_concepts_df.pkl', 'rb') as f:\n",
    "    eurovoc_concepts_df = pickle.load(f)\n",
    "with open('./data/preprocessed/cumulative.pkl', 'rb') as f:\n",
    "    cumulative = pickle.load(f)\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(cumulative['eurovoc_concepts_limited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commented out for safety since it takes a long time to run. It's advised to load from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_lg', exclude=['parser', 'ner'])\n",
    "\n",
    "# def preprocess(text):\n",
    "#     # TODO: Replace the next line with your own code.\n",
    "#     doc = nlp(text)\n",
    "#     data = [(token.lemma_) for token in doc if token.is_alpha and not token.is_stop and token.lemma_.isalpha()]\n",
    "#     data = pd.DataFrame(data, columns=['lemma'])\n",
    "#     return list(data.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()\n",
    "\n",
    "# train['preprocessed'] = train['text'].apply(preprocess)\n",
    "# test['preprocessed'] = test['text'].apply(preprocess)\n",
    "# val['preprocessed'] = val['text'].apply(preprocess)\n",
    "# cumulative = pd.concat([train, test, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_count = cumulative.explode('eurovoc_concepts').groupby('eurovoc_concepts').count().reset_index()\n",
    "# labels_count = labels_count[['eurovoc_concepts', 'text']]\n",
    "# labels_count.columns = ['eurovoc_concepts', 'count']\n",
    "# labels_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# # plot histogram of the number of documents per class\n",
    "# plt.hist(labels_count['count'], bins=100, range=(0, 600))\n",
    "# plt.xlabel('Number of documents')\n",
    "# plt.ylabel('Number of classes')\n",
    "# plt.bar(500, labels_count[labels_count['count'] >= 500].count(), color='black', width=5)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of classes with less than 10 documents\n",
    "# print(f'Number of classes with less than 10 documents: {labels_count[labels_count[\"count\"] < 10].count().values[0]}')\n",
    "\n",
    "# # Number of classes with less than 50 documents\n",
    "# print(f'Number of classes with less than 50 documents: {labels_count[labels_count[\"count\"] < 50].count().values[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only labels that have more than 10 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_count = labels_count[labels_count['count'] >= 10].reset_index(drop=True)\n",
    "\n",
    "# eurovoc_concepts_df = eurovoc_concepts_df[eurovoc_concepts_df['id'].isin(labels_count['eurovoc_concepts'])].sort_values(by='id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove classes with less than 10 documents from the dataset and keep the ones left\n",
    "\n",
    "# train['eurovoc_concepts_limited'] = train['eurovoc_concepts'].apply(lambda x: [i for i in x if i in labels_count['eurovoc_concepts'].values])\n",
    "# train = train[train['eurovoc_concepts_limited'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "# test['eurovoc_concepts_limited'] = test['eurovoc_concepts'].apply(lambda x: [i for i in x if i in labels_count['eurovoc_concepts'].values])\n",
    "# test = test[test['eurovoc_concepts_limited'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "# val['eurovoc_concepts_limited'] = val['eurovoc_concepts'].apply(lambda x: [i for i in x if i in labels_count['eurovoc_concepts'].values])\n",
    "# val = val[val['eurovoc_concepts_limited'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "# cumulative = pd.concat([train, test, val], keys=['train', 'test', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# y = mlb.fit_transform(cumulative['eurovoc_concepts_limited'])\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = cumulative.loc['train', 'preprocessed'].reset_index(drop=True)\n",
    "# x_test = cumulative.loc['test', 'preprocessed'].reset_index(drop=True)\n",
    "# x_val = cumulative.loc['val', 'preprocessed'].reset_index(drop=True)\n",
    "\n",
    "# y_train = y[:len(x_train)].copy()\n",
    "# y_test = y[len(x_train):len(x_train)+len(x_test)].copy()\n",
    "# y_val = y[len(x_train)+len(x_test):].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the data to disk for later use\n",
    "# import pickle\n",
    "# with open('./data/preprocessed/x_train.pkl', 'wb') as f:\n",
    "#     pickle.dump(x_train, f)\n",
    "# with open('./data/preprocessed/x_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(x_test, f)\n",
    "# with open('./data/preprocessed/x_val.pkl', 'wb') as f:\n",
    "#     pickle.dump(x_val, f)\n",
    "# with open('./data/preprocessed/y_train.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_train, f)\n",
    "# with open('./data/preprocessed/y_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_test, f)\n",
    "# with open('./data/preprocessed/y_val.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_val, f)\n",
    "# with open('./data/preprocessed/y.pkl', 'wb') as f:\n",
    "#     pickle.dump(y, f)\n",
    "# with open('./data/preprocessed/eurovoc_concepts_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(eurovoc_concepts_df, f)\n",
    "# with open('./data/preprocessed/cumulative.pkl', 'wb') as f:\n",
    "#     pickle.dump(cumulative, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTagDataset(Dataset):\n",
    "    def __init__(self,quest,tags, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = quest\n",
    "        self.labels = tags\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item_idx):\n",
    "        text = self.text[item_idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True, # Add [CLS] [SEP]\n",
    "            max_length= self.max_len,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids= False,\n",
    "            return_attention_mask= True, # Differentiates padded vs normal token\n",
    "            truncation=True, # Truncate data beyond max length\n",
    "            return_tensors = 'pt' # PyTorch Tensor format\n",
    "          )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "        #token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids ,\n",
    "            'attention_mask': attn_mask,\n",
    "            'label': torch.tensor(self.labels[item_idx], dtype=torch.float)\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTagDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self,x_tr,y_tr,x_val,y_val,x_test,y_test,tokenizer,batch_size=16,max_token_len=200):\n",
    "        super().__init__()\n",
    "        self.tr_text = x_tr\n",
    "        self.tr_label = y_tr\n",
    "        self.val_text = x_val\n",
    "        self.val_label = y_val\n",
    "        self.test_text = x_test\n",
    "        self.test_label = y_test\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, **kwargs):\n",
    "        self.train_dataset = QTagDataset(quest=self.tr_text, tags=self.tr_label, tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.val_dataset  = QTagDataset(quest=self.val_text,tags=self.val_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.test_dataset  = QTagDataset(quest=self.test_text,tags=self.test_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader (self.train_dataset,batch_size = self.batch_size,shuffle = True , num_workers=8, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader (self.val_dataset,batch_size= 16, num_workers=8, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader (self.test_dataset,batch_size= 16, num_workers=8, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Bert tokenizer\n",
    "BERT_MODEL_NAME = \"nlpaueb/legal-bert-base-uncased\" # we will use the BERT base model(the smaller one)\n",
    "Bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Question having word count > 512: is  5888 out of 56979\n"
     ]
    }
   ],
   "source": [
    "max_word_cnt = 512\n",
    "quest_cnt = 0\n",
    "\n",
    "# For every sentence...\n",
    "for question in cumulative['preprocessed']:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = Bert_tokenizer.encode(question, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    if len(input_ids) > max_word_cnt:\n",
    "        quest_cnt +=1\n",
    "\n",
    "print(f'# Question having word count > {max_word_cnt}: is  {quest_cnt} out of {len(cumulative)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters that will be use for training\n",
    "N_EPOCHS = 300\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 500\n",
    "LR = 2e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and set up the data_module\n",
    "QTdata_module = QTagDataModule(x_train,y_train,x_val,y_val,x_test,y_test,Bert_tokenizer,BATCH_SIZE,MAX_LEN)\n",
    "QTdata_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTagClassifier(pl.LightningModule):\n",
    "    # Set up the classifier\n",
    "    def __init__(self, n_classes=10, steps_per_epoch=None, n_epochs=3, lr=2e-5 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size,n_classes) # outputs = number of labels\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self,input_ids, attn_mask):\n",
    "        output = self.bert(input_ids = input_ids ,attention_mask = attn_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('train_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return {\"loss\" :loss, \"predictions\":outputs, \"labels\": labels }\n",
    "\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('val_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('test_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters() , lr=self.lr)\n",
    "        warmup_steps = self.steps_per_epoch//3\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,total_steps)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier model\n",
    "steps_per_epoch = len(x_train)//BATCH_SIZE\n",
    "model = QTagClassifier(n_classes=y.shape[1], steps_per_epoch=steps_per_epoch,n_epochs=N_EPOCHS,lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Pytorch Lightning callback for Model checkpointing\n",
    "\n",
    "# saves a file like: input/QTag-epoch=02-val_loss=0.32.ckpt\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='legalbert_model',\n",
    "    monitor='val_loss',# monitored quantity\n",
    "    filename='Legal_500-{epoch:02d}-{val_loss:.5f}',\n",
    "    save_top_k=3, #  save the top 3 models\n",
    "    mode='min', # mode of the monitored quantity  for optimization\n",
    "    save_last=True, # save the last model\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Initialize Pytorch Lightning callback for Early Stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00,\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Model logger\n",
    "logger = TensorBoardLogger('lightning_logs', name='LegalBert_500')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:55: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v2.0. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Model Trainer\n",
    "trainer = pl.Trainer(max_epochs = N_EPOCHS ,accelerator='auto', devices=[0], callbacks=[checkpoint_callback, early_stop_callback], enable_progress_bar=True, precision=16, amp_backend=\"native\", logger=logger, resume_from_checkpoint='legalbert_model/Legal_500-epoch=189-val_loss=0.00521.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  4 18:57:55 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 25%   44C    P2    32W / 215W |    737MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1908: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v2.0. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /workspace/LiU/732A81 - Text Mining project/legalbert_model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Restoring states from the checkpoint path at legalbert_model/Legal_500-epoch=189-val_loss=0.00521.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | bert       | BertModel         | 109 M \n",
      "1 | classifier | Linear            | 1.6 M \n",
      "2 | criterion  | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------------\n",
      "111 M     Trainable params\n",
      "0         Non-trainable params\n",
      "111 M     Total params\n",
      "222.116   Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint file at legalbert_model/Legal_500-epoch=189-val_loss=0.00521.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847a6488e75e47b7b749f840249b2678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4955f4d6c764955a0330e0ed16bbc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 2812it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# Train the Classifier Model\n",
    "trainer.fit(model, QTdata_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at old_models/legalbert_model/Legal_500-epoch=189-val_loss=0.00521.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at old_models/legalbert_model/Legal_500-epoch=189-val_loss=0.00521.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0dccf38de634fd2af7e4ca0f69c88f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.005286832340061665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.005286832340061665}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model performance on the test dataset\n",
    "trainer.test(model,datamodule=QTdata_module, ckpt_path='old_models/legalbert_model/Legal_500-epoch=189-val_loss=0.00521.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a2df3244c09217d6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a2df3244c09217d6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the logs using tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retreive the checkpoint path for best model\n",
    "model_path = checkpoint_callback.best_model_path\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5995, 5995)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents = 5995\n"
     ]
    }
   ],
   "source": [
    "# Size of Test set\n",
    "print(f'Number of Documents = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup test dataset for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Tokenize all questions in x_test\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "\n",
    "for quest in x_test:\n",
    "    encoded_quest =  Bert_tokenizer.encode_plus(\n",
    "                    quest,\n",
    "                    None,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length= MAX_LEN,\n",
    "                    padding = 'max_length',\n",
    "                    return_token_type_ids= False,\n",
    "                    return_attention_mask= True,\n",
    "                    truncation=True,\n",
    "                    return_tensors = 'pt'      \n",
    "    )\n",
    "    \n",
    "    # Add the input_ids from encoded question to the list.    \n",
    "    input_ids.append(encoded_quest['input_ids'])\n",
    "    # Add its attention mask \n",
    "    attention_masks.append(encoded_quest['attention_mask'])\n",
    "    \n",
    "# Now convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(y_test)\n",
    "\n",
    "# Set the batch size.  \n",
    "TEST_BATCH_SIZE = 64  \n",
    "\n",
    "# Create the DataLoader.\n",
    "pred_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "pred_sampler = SequentialSampler(pred_data)\n",
    "pred_dataloader = DataLoader(pred_data, sampler=pred_sampler, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,   100,   100,   100,   100,   100,   100,   100,   100,   273,\n",
       "           100,  1836,  1367,   100,   100,   100,   100,   672,   399,  1399,\n",
       "           794,   295,   100,   100,   100,   100,  1227,   651,   100,   100,\n",
       "          2895,   100,   100,   100,   247,   374,   100,   100,   100,   100,\n",
       "           247,   374,   100,   100,   100,   100,  1008,  3583,   411,  1258,\n",
       "          3253,   375,  2505,   919,   919,   424,  2886,   100,   100, 30519,\n",
       "           100,   100,   100,   382,  1567,  1361,   234,   100,   375,   360,\n",
       "           100,  1967,  1008,  3583,  1258,   540,  3253,   916,   100,   772,\n",
       "           294,   360,   100,  3338,  3169,   916,   794,   100,   100,  4858,\n",
       "           573,   919,   919,   424,  1294,   360,   309,  1927,   794,  2161,\n",
       "           399,   284,  1021,  1115,   374,  1718,   540,  3253,  1258,   916,\n",
       "           100,   399,  4608,   485,   100,  1750,   411,  1876,  3190,   369,\n",
       "           100,   100,   100,  3042,   399,   462,   100,   100,   100,   399,\n",
       "          1399,   411,   794,   916,   100,   772,   919,   919,   424,  2147,\n",
       "           916,   273,   100,  2886,  3102,   100,   100,   100,   100,   672,\n",
       "          3253,  1718,   399,  1399,   794,   295,   100,   100,   100,   901,\n",
       "          2243,   399,  1399,   411,   794,   536,   286,  1150,   100,   369,\n",
       "          4608,   916,   794,   100,   100,  4858,   573,   411,   919,   919,\n",
       "           424,   462,   100,   100,  1884,   916,   100,   273,   100,   916,\n",
       "           100,  1884,   698,   916,   100,  7318,   100,   462,   399,   960,\n",
       "           100,   100,   100,   100,  3068,   916,   100,  1399,   399,  7318,\n",
       "           100,   399,   462,   885,  1021,  3042,  1003,   100,  7318,   698,\n",
       "           916,   100,  1518,  5079,  1008,   785, 24009,  3253,   399,  7318,\n",
       "           794,  1399,  4882,  3253,   399,  7318,   100,  1829,  3046,  2058,\n",
       "           965,   399,  1003,   100,   916,   698,  7318,   100,  1399,   399,\n",
       "          7318,   100,   399,   462,   885,  1021,  3042,  7318,   698,  1003,\n",
       "           100,   916,   100,  1884,   698,   916,   100,   538,  2561,   100,\n",
       "           273,   100,  2561,  2876,   573,   794,  2584,   397,   100,   100,\n",
       "           794,  3042,   573,  2584,   397,   100,   295,   100,   273,   100,\n",
       "           462,   960,  1021,   399,   100,  1003,   794,   916,   915,   698,\n",
       "           100,   100,  1399,   399,  3779,   100,   399,   462,   885,  1021,\n",
       "          3042,  3779,   698,  1003,   100,   916,  1003,   100,   916,   698,\n",
       "           100,   538,  2561,   100,   273,   100,   100,   273,   100,  1836,\n",
       "           100,   100,   100,   538,  2561,   100,  1399,  3042,   399,   100,\n",
       "           100,  4173,   581,   672,   399,  1003,   794,   916,  1367,  7113,\n",
       "           538,  2561,   573,   100,   744,   384,  3680,  1003,   100,   549,\n",
       "           100,   100,   254,   352,   273,   100,  1675,  1003,   100,  2008,\n",
       "           791,   434,   100,   100,  1858,  1015,  6508,   573,   594,   100,\n",
       "           100,   273,   100,  1836,  1015,  1008,   462,   273,   295,   528,\n",
       "           100,   100,   100,   100,   100,   100,   100,   273,   100,  3102,\n",
       "          1314,   100,   273,   273,   224,   549,   100,   543,  2161,  1003,\n",
       "           100,   224,   549,   100,   273,   785,   100,   100,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0,  ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5995"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_pred_outs = 0\n",
    "flat_true_labels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QTagClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2049, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put model in evaluation mode\n",
    "model = model.to(device) # moving model to cuda\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "pred_outs, true_labels = [], []\n",
    "#i=0\n",
    "# Predict \n",
    "for batch in pred_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_attn_mask, b_labels = batch\n",
    " \n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        pred_out = model(b_input_ids,b_attn_mask)\n",
    "        pred_out = torch.sigmoid(pred_out)\n",
    "        # Move predicted output and labels to CPU\n",
    "        pred_out = pred_out.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        #i+=1\n",
    "        # Store predictions and true labels\n",
    "        #print(i)\n",
    "        #print(outputs)\n",
    "        #print(logits)\n",
    "        #print(label_ids)\n",
    "    pred_outs.append(pred_out)\n",
    "    true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00150527, 0.03212523, 0.00014549, ..., 0.00252681, 0.00040853,\n",
       "       0.00024695], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_outs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5995, 2049), (5995, 2049))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_pred_outs.shape , flat_true_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions of Tags in Test set\n",
    "The predictions are in terms of logits (probabilities for each of the 16 tags). Hence we need to have a threshold value to convert these probabilities to 0 or 1.\n",
    "\n",
    "Let's specify a set of candidate threshold values. We will select the threshold value that performs the best for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that takes a threshold value and uses it to convert probabilities into 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities into 0 or 1 based on a threshold value\n",
    "def classify(pred_prob,thresh):\n",
    "    y_pred = []\n",
    "\n",
    "    for tag_label_row in pred_prob:\n",
    "        temp=[]\n",
    "        for tag_label in tag_label_row:\n",
    "            if tag_label >= thresh:\n",
    "                temp.append(1) # Infer tag value as 1 (present)\n",
    "            else:\n",
    "                temp.append(0) # Infer tag value as 0 (absent)\n",
    "        y_pred.append(temp)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_true_labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "scores=[] # Store the list of f1 scores for prediction on each threshold\n",
    "\n",
    "#convert labels to 1D array\n",
    "y_true = flat_true_labels.ravel() \n",
    "\n",
    "# for thresh in threshold:\n",
    "    \n",
    "#classes for each threshold\n",
    "pred_bin_label = classify(flat_pred_outs,0.5) \n",
    "\n",
    "#convert to 1D array\n",
    "y_pred = np.array(pred_bin_label).ravel()\n",
    "\n",
    "scores.append(metrics.f1_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Score Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00  12254176\n",
      "           1       0.80      0.55      0.65     29579\n",
      "\n",
      "    accuracy                           1.00  12283755\n",
      "   macro avg       0.90      0.77      0.82  12283755\n",
      "weighted avg       1.00      1.00      1.00  12283755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions for optimal threshold\n",
    "y_pred_labels = classify(flat_pred_outs,0.5)\n",
    "y_pred = np.array(y_pred_labels).ravel() # Flatten\n",
    "\n",
    "print(metrics.classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8dfd2c19a0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Threshold')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1 score')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = np.arange(0.1, 1, 0.05)\n",
    "f1_scores = []\n",
    "y_true = flat_true_labels.ravel() \n",
    "for threshold in thresholds:\n",
    "    y_pred_labels = classify(flat_pred_outs, threshold)\n",
    "    y_pred = np.array(y_pred_labels).ravel() # Flatten\n",
    "    \n",
    "    f1_scores.append(metrics.classification_report(y_true, y_pred, output_dict=True)['macro avg']['f1-score'])\n",
    "\n",
    "# plot the F1 score for different thresholds\n",
    "plt.plot(thresholds, f1_scores)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlb.inverse_transform(np.array(y_pred_labels))\n",
    "y_act = mlb.inverse_transform(flat_true_labels)\n",
    "\n",
    "df = pd.DataFrame({'Body':x_test,'Actual Tags':y_act,'Predicted Tags':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Actual Tags</th>\n",
       "      <th>Predicted Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>[COUNCIL, REGULATION, EC, April, amend, Regula...</td>\n",
       "      <td>(1309, 2084, 2437, 2771, 4402, 519)</td>\n",
       "      <td>(1309,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>[EN, Official, Journal, European, Union, L, CO...</td>\n",
       "      <td>(1501, 3483, 3870)</td>\n",
       "      <td>(3483, 3870)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>[COMMISSION, decision, December, implementatio...</td>\n",
       "      <td>(1958, 2970, 2971, 336, 889, 980)</td>\n",
       "      <td>(1958, 2971, 980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>[COMMISSION, REGULATION, EEC, December, abolis...</td>\n",
       "      <td>(2563, 2734, 2957, 4333, 863)</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>[EN, Official, Journal, European, Union, L, CO...</td>\n",
       "      <td>(1309, 161, 1644, 2743, 4682)</td>\n",
       "      <td>(161, 2743)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>[EN, Official, Journal, European, Union, L, CO...</td>\n",
       "      <td>(2110, 2282, 2437, 2879, 544, 598, 605, 863)</td>\n",
       "      <td>(2437, 2879, 544)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>[EN, Official, Journal, European, Union, L, CO...</td>\n",
       "      <td>(1117, 1519, 3173, 5573)</td>\n",
       "      <td>(3173, 5573)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>[COMMISSION, REGULATION, EEC, July, amend, Reg...</td>\n",
       "      <td>(2871, 3170, 6042)</td>\n",
       "      <td>(6042,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>[COUNCIL, DECISION, January, authorise, Kingdo...</td>\n",
       "      <td>(1234, 2897, 343, 4585, 5581, 863)</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>[EN, Official, Journal, European, Union, L, CO...</td>\n",
       "      <td>(161, 1644, 2121, 2212, 3191)</td>\n",
       "      <td>(161, 1644, 2121)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Body  \\\n",
       "2404  [COUNCIL, REGULATION, EC, April, amend, Regula...   \n",
       "1916  [EN, Official, Journal, European, Union, L, CO...   \n",
       "2503  [COMMISSION, decision, December, implementatio...   \n",
       "2513  [COMMISSION, REGULATION, EEC, December, abolis...   \n",
       "2024  [EN, Official, Journal, European, Union, L, CO...   \n",
       "2233  [EN, Official, Journal, European, Union, L, CO...   \n",
       "710   [EN, Official, Journal, European, Union, L, CO...   \n",
       "3360  [COMMISSION, REGULATION, EEC, July, amend, Reg...   \n",
       "1350  [COUNCIL, DECISION, January, authorise, Kingdo...   \n",
       "2313  [EN, Official, Journal, European, Union, L, CO...   \n",
       "\n",
       "                                       Actual Tags     Predicted Tags  \n",
       "2404           (1309, 2084, 2437, 2771, 4402, 519)            (1309,)  \n",
       "1916                            (1501, 3483, 3870)       (3483, 3870)  \n",
       "2503             (1958, 2970, 2971, 336, 889, 980)  (1958, 2971, 980)  \n",
       "2513                 (2563, 2734, 2957, 4333, 863)                 ()  \n",
       "2024                 (1309, 161, 1644, 2743, 4682)        (161, 2743)  \n",
       "2233  (2110, 2282, 2437, 2879, 544, 598, 605, 863)  (2437, 2879, 544)  \n",
       "710                       (1117, 1519, 3173, 5573)       (3173, 5573)  \n",
       "3360                            (2871, 3170, 6042)            (6042,)  \n",
       "1350            (1234, 2897, 343, 4585, 5581, 863)                 ()  \n",
       "2313                 (161, 1644, 2121, 2212, 3191)  (161, 1644, 2121)  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e4948375748b4327b745d5a2dae00a5af67158785800fa79ee8701babd6dc22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
