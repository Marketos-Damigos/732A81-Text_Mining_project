{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"datasets\" \"scikit-learn\" \"torchmetrics>=0.7\" \"scipy\" \"pytorch-lightning==1.8.6\" \"transformers\" \"torchtext>=0.9\" \"setuptools==59.5.0\" \"ipython[notebook]\" \"torch==1.13\" \"seaborn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install 'torch==1.13' torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LiU/732A81 - Text Mining project\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "%cd LiU/732A81 - Text Mining project\n",
    "%pwd\n",
    "\n",
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Huggingface transformers\n",
    "import transformers\n",
    "from transformers import BertModel,BertTokenizer,AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "#handling html data\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: eurlex/eurlex57k\n",
      "Found cached dataset eurlex (/root/.cache/huggingface/datasets/eurlex/eurlex57k/1.1.0/d2fdeaa4fcb5f41394d2ed0317c8541d7f9be85d2d601b9fa586c8b461bc3a34)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b85d9874b041d3a0bee862dcb1ed8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('eurlex')\n",
    "#eurovoc_concepts_df = pd.read_json('./data/datasets/EURLEX57K/eurovoc_concepts.jsonl', lines=True)\n",
    "\n",
    "train = pd.DataFrame(dataset['train'])\n",
    "test = pd.DataFrame(dataset['test'])\n",
    "val = pd.DataFrame(dataset['validation'])\n",
    "#cumulative = pd.concat([train, test, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from disk\n",
    "import pickle\n",
    "with open('./data/preprocessed_title/x_train.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with open('./data/preprocessed_title/x_test.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "with open('./data/preprocessed_title/x_val.pkl', 'rb') as f:\n",
    "    x_val = pickle.load(f)\n",
    "with open('./data/preprocessed_title/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('./data/preprocessed_title/y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "with open('./data/preprocessed_title/y_val.pkl', 'rb') as f:\n",
    "    y_val = pickle.load(f)\n",
    "with open('./data/preprocessed_title/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "with open('./data/preprocessed_title/eurovoc_concepts_df.pkl', 'rb') as f:\n",
    "    eurovoc_concepts_df = pickle.load(f)\n",
    "with open('./data/preprocessed_title/cumulative.pkl', 'rb') as f:\n",
    "    cumulative = pickle.load(f)\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(cumulative['eurovoc_concepts_limited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commented out for safety since it takes a long time to run. It's advised to load from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_lg', exclude=['parser', 'ner'])\n",
    "\n",
    "# def preprocess(text):\n",
    "#     # TODO: Replace the next line with your own code.\n",
    "#     doc = nlp(text)\n",
    "#     data = [(token.lemma_) for token in doc if token.is_alpha and not token.is_stop and token.lemma_.isalpha()]\n",
    "#     data = pd.DataFrame(data, columns=['lemma'])\n",
    "#     return list(data.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()\n",
    "\n",
    "# train['preprocessed'] = train['title'].apply(preprocess)\n",
    "# test['preprocessed'] = test['title'].apply(preprocess)\n",
    "# val['preprocessed'] = val['title'].apply(preprocess)\n",
    "# cumulative = pd.concat([train, test, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_count = cumulative.explode('eurovoc_concepts').groupby('eurovoc_concepts').count().reset_index()\n",
    "# labels_count = labels_count[['eurovoc_concepts', 'text']]\n",
    "# labels_count.columns = ['eurovoc_concepts', 'count']\n",
    "# labels_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# # plot histogram of the number of documents per class\n",
    "# plt.hist(labels_count['count'], bins=100, range=(0, 600))\n",
    "# plt.xlabel('Number of documents')\n",
    "# plt.ylabel('Number of classes')\n",
    "# plt.bar(500, labels_count[labels_count['count'] >= 500].count(), color='black', width=5)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of classes with less than 10 documents\n",
    "# print(f'Number of classes with less than 10 documents: {labels_count[labels_count[\"count\"] < 10].count().values[0]}')\n",
    "\n",
    "# # Number of classes with less than 50 documents\n",
    "# print(f'Number of classes with less than 50 documents: {labels_count[labels_count[\"count\"] < 50].count().values[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only labels that have more than 10 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_count = labels_count[labels_count['count'] >= 10].reset_index(drop=True)\n",
    "\n",
    "# eurovoc_concepts_df = eurovoc_concepts_df[eurovoc_concepts_df['id'].isin(labels_count['eurovoc_concepts'])].sort_values(by='id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove classes with less than 10 documents from the dataset and keep the ones left\n",
    "\n",
    "# train['eurovoc_concepts_limited'] = train['eurovoc_concepts'].apply(lambda x: [i for i in x if i in labels_count['eurovoc_concepts'].values])\n",
    "# train = train[train['eurovoc_concepts_limited'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "# test['eurovoc_concepts_limited'] = test['eurovoc_concepts'].apply(lambda x: [i for i in x if i in labels_count['eurovoc_concepts'].values])\n",
    "# test = test[test['eurovoc_concepts_limited'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "# val['eurovoc_concepts_limited'] = val['eurovoc_concepts'].apply(lambda x: [i for i in x if i in labels_count['eurovoc_concepts'].values])\n",
    "# val = val[val['eurovoc_concepts_limited'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "# cumulative = pd.concat([train, test, val], keys=['train', 'test', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# y = mlb.fit_transform(cumulative['eurovoc_concepts_limited'])\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = cumulative.loc['train', 'preprocessed'].reset_index(drop=True)\n",
    "# x_test = cumulative.loc['test', 'preprocessed'].reset_index(drop=True)\n",
    "# x_val = cumulative.loc['val', 'preprocessed'].reset_index(drop=True)\n",
    "\n",
    "# y_train = y[:len(x_train)].copy()\n",
    "# y_test = y[len(x_train):len(x_train)+len(x_test)].copy()\n",
    "# y_val = y[len(x_train)+len(x_test):].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the data to disk for later use\n",
    "# import pickle\n",
    "# with open('./data/preprocessed_title/x_train.pkl', 'wb') as f:\n",
    "#     pickle.dump(x_train, f)\n",
    "# with open('./data/preprocessed_title/x_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(x_test, f)\n",
    "# with open('./data/preprocessed_title/x_val.pkl', 'wb') as f:\n",
    "#     pickle.dump(x_val, f)\n",
    "# with open('./data/preprocessed_title/y_train.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_train, f)\n",
    "# with open('./data/preprocessed_title/y_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_test, f)\n",
    "# with open('./data/preprocessed_title/y_val.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_val, f)\n",
    "# with open('./data/preprocessed_title/y.pkl', 'wb') as f:\n",
    "#     pickle.dump(y, f)\n",
    "# with open('./data/preprocessed_title/eurovoc_concepts_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(eurovoc_concepts_df, f)\n",
    "# with open('./data/preprocessed_title/cumulative.pkl', 'wb') as f:\n",
    "#     pickle.dump(cumulative, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTagDataset(Dataset):\n",
    "    def __init__(self,quest,tags, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = quest\n",
    "        self.labels = tags\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item_idx):\n",
    "        text = self.text[item_idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True, # Add [CLS] [SEP]\n",
    "            max_length= self.max_len,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids= False,\n",
    "            return_attention_mask= True, # Differentiates padded vs normal token\n",
    "            truncation=True, # Truncate data beyond max length\n",
    "            return_tensors = 'pt' # PyTorch Tensor format\n",
    "          )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "        #token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids ,\n",
    "            'attention_mask': attn_mask,\n",
    "            'label': torch.tensor(self.labels[item_idx], dtype=torch.float)\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTagDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self,x_tr,y_tr,x_val,y_val,x_test,y_test,tokenizer,batch_size=16,max_token_len=200):\n",
    "        super().__init__()\n",
    "        self.tr_text = x_tr\n",
    "        self.tr_label = y_tr\n",
    "        self.val_text = x_val\n",
    "        self.val_label = y_val\n",
    "        self.test_text = x_test\n",
    "        self.test_label = y_test\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, **kwargs):\n",
    "        self.train_dataset = QTagDataset(quest=self.tr_text, tags=self.tr_label, tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.val_dataset  = QTagDataset(quest=self.val_text,tags=self.val_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.test_dataset  = QTagDataset(quest=self.test_text,tags=self.test_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader (self.train_dataset,batch_size = self.batch_size,shuffle = True , num_workers=8, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader (self.val_dataset,batch_size= 16, num_workers=8, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader (self.test_dataset,batch_size= 16, num_workers=8, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Bert tokenizer\n",
    "BERT_MODEL_NAME = \"nlpaueb/legal-bert-base-uncased\" # we will use the BERT base model(the smaller one)\n",
    "Bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Question having word count > 512: is  0 out of 56979\n"
     ]
    }
   ],
   "source": [
    "max_word_cnt = 512\n",
    "quest_cnt = 0\n",
    "\n",
    "# For every sentence...\n",
    "for question in cumulative['preprocessed']:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = Bert_tokenizer.encode(question, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    if len(input_ids) > max_word_cnt:\n",
    "        quest_cnt +=1\n",
    "\n",
    "print(f'# Question having word count > {max_word_cnt}: is  {quest_cnt} out of {len(cumulative)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters that will be use for training\n",
    "N_EPOCHS = 300\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 300\n",
    "LR = 2e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and set up the data_module\n",
    "QTdata_module = QTagDataModule(x_train,y_train,x_val,y_val,x_test,y_test,Bert_tokenizer,BATCH_SIZE,MAX_LEN)\n",
    "QTdata_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTagClassifier(pl.LightningModule):\n",
    "    # Set up the classifier\n",
    "    def __init__(self, n_classes=10, steps_per_epoch=None, n_epochs=3, lr=2e-5 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size,n_classes) # outputs = number of labels\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self,input_ids, attn_mask):\n",
    "        output = self.bert(input_ids = input_ids ,attention_mask = attn_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('train_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return {\"loss\" :loss, \"predictions\":outputs, \"labels\": labels }\n",
    "\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('val_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('test_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters() , lr=self.lr)\n",
    "        warmup_steps = self.steps_per_epoch//3\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,total_steps)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier model\n",
    "steps_per_epoch = len(x_train)//BATCH_SIZE\n",
    "model = QTagClassifier(n_classes=y.shape[1], steps_per_epoch=steps_per_epoch,n_epochs=N_EPOCHS,lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Pytorch Lightning callback for Model checkpointing\n",
    "\n",
    "# saves a file like: input/QTag-epoch=02-val_loss=0.32.ckpt\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='legalbert_model_with_titles',\n",
    "    monitor='val_loss',# monitored quantity\n",
    "    filename='Legal_titles-{epoch:02d}-{val_loss:.5f}',\n",
    "    save_top_k=3, #  save the top 3 models\n",
    "    mode='min', # mode of the monitored quantity  for optimization\n",
    "    save_last=True, # save the last model\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Initialize Pytorch Lightning callback for Early Stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00,\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Model logger\n",
    "logger = TensorBoardLogger('lightning_logs', name='LegalBert_titles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Model Trainer\n",
    "trainer = pl.Trainer(max_epochs = N_EPOCHS ,accelerator='auto', devices=[0], callbacks=[checkpoint_callback, early_stop_callback], enable_progress_bar=True, precision=16, amp_backend=\"native\", logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  4 20:27:14 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   45C    P8    13W / 220W |    300MiB /  8192MiB |     22%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /workspace/LiU/732A81 - Text Mining project/legalbert_model_with_titles exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | bert       | BertModel         | 109 M \n",
      "1 | classifier | Linear            | 1.6 M \n",
      "2 | criterion  | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------------\n",
      "111 M     Trainable params\n",
      "0         Non-trainable params\n",
      "111 M     Total params\n",
      "222.116   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42cef86a1084d648718596912bfc5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84438d4397f54075afd966ab65fc5301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# Train the Classifier Model\n",
    "trainer.fit(model, QTdata_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at old_models/legalbert_model_with_titles/Legal_titles-epoch=209-val_loss=0.00542.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at old_models/legalbert_model_with_titles/Legal_titles-epoch=209-val_loss=0.00542.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a68b771dd847b080440b4e59db21dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.0055004931055009365\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0055004931055009365}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model performance on the test dataset\n",
    "trainer.test(model,datamodule=QTdata_module, ckpt_path='old_models/legalbert_model_with_titles/Legal_titles-epoch=209-val_loss=0.00542.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a2df3244c09217d6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a2df3244c09217d6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the logs using tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive the checkpoint path for best model from disk\n",
    "\n",
    "# Get the path of the best model\n",
    "model_path = 'legalbert_model_with_titles/Legal_titles-epoch=209-val_loss=0.00542.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5995, 5995)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents = 5995\n"
     ]
    }
   ],
   "source": [
    "# Size of Test set\n",
    "print(f'Number of Documents = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup test dataset for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Tokenize all questions in x_test\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "\n",
    "for quest in x_test:\n",
    "    encoded_quest =  Bert_tokenizer.encode_plus(\n",
    "                    quest,\n",
    "                    None,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length= MAX_LEN,\n",
    "                    padding = 'max_length',\n",
    "                    return_token_type_ids= False,\n",
    "                    return_attention_mask= True,\n",
    "                    truncation=True,\n",
    "                    return_tensors = 'pt'      \n",
    "    )\n",
    "    \n",
    "    # Add the input_ids from encoded question to the list.    \n",
    "    input_ids.append(encoded_quest['input_ids'])\n",
    "    # Add its attention mask \n",
    "    attention_masks.append(encoded_quest['attention_mask'])\n",
    "    \n",
    "# Now convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(y_test)\n",
    "\n",
    "# Set the batch size.  \n",
    "TEST_BATCH_SIZE = 64  \n",
    "\n",
    "# Create the DataLoader.\n",
    "pred_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "pred_sampler = SequentialSampler(pred_data)\n",
    "pred_dataloader = DataLoader(pred_data, sampler=pred_sampler, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 101,  100, 2397,  100,  100, 1836, 1367,  100,  100,  100,  100,  672,\n",
       "          399, 1399,  794,  295,  234,  100,  100,  100, 1227,  651, 1314, 1663,\n",
       "         2895,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0,  ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5995"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_pred_outs = 0\n",
    "flat_true_labels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QTagClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2049, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put model in evaluation mode\n",
    "model = model.to(device) # moving model to cuda\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "pred_outs, true_labels = [], []\n",
    "#i=0\n",
    "# Predict \n",
    "for batch in pred_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_attn_mask, b_labels = batch\n",
    " \n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        pred_out = model(b_input_ids,b_attn_mask)\n",
    "        pred_out = torch.sigmoid(pred_out)\n",
    "        # Move predicted output and labels to CPU\n",
    "        pred_out = pred_out.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # i+=1\n",
    "        # #Store predictions and true labels\n",
    "        # print(i)\n",
    "        # print(outputs)\n",
    "        # print(logits)\n",
    "        # print(label_ids)\n",
    "    pred_outs.append(pred_out)\n",
    "    true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 2049)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m (pred_outs[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mshape\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(pred_outs\u001b[39m.\u001b[39;49mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "(pred_outs[0]).shape\n",
    "\n",
    "print(pred_outs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(true_labels[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5995, 2049), (5995, 2049))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_pred_outs.shape , flat_true_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.46584857e-04, 2.67996197e-03, 1.50957567e-04, ...,\n",
       "        4.48089151e-04, 4.86372955e-05, 7.03531550e-05],\n",
       "       [5.86799933e-06, 4.46607373e-06, 1.02724434e-05, ...,\n",
       "        3.29661179e-06, 1.31615679e-05, 2.26070597e-06],\n",
       "       [1.43608358e-05, 1.10853416e-05, 2.47549656e-06, ...,\n",
       "        1.89651128e-05, 1.19576915e-04, 2.59296703e-05],\n",
       "       ...,\n",
       "       [7.43685523e-05, 4.43305908e-05, 1.84581877e-04, ...,\n",
       "        6.67782342e-06, 1.21429628e-04, 3.13362107e-04],\n",
       "       [1.05516265e-04, 4.06543637e-04, 1.51763918e-04, ...,\n",
       "        1.35363734e-04, 9.31357499e-06, 2.02546489e-05],\n",
       "       [4.06443942e-05, 3.71630420e-03, 3.67778603e-06, ...,\n",
       "        5.00009482e-05, 1.46614702e-05, 1.01522928e-05]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_pred_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99700254"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_pred_outs[1].max()\n",
    "flat_true_labels[1].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions of Tags in Test set\n",
    "The predictions are in terms of logits (probabilities for each of the 16 tags). Hence we need to have a threshold value to convert these probabilities to 0 or 1.\n",
    "\n",
    "Let's specify a set of candidate threshold values. We will select the threshold value that performs the best for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define candidate threshold values\n",
    "threshold  = 0.5\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that takes a threshold value and uses it to convert probabilities into 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities into 0 or 1 based on a threshold value\n",
    "def classify(pred_prob,thresh):\n",
    "    y_pred = []\n",
    "\n",
    "    for tag_label_row in pred_prob:\n",
    "        temp=[]\n",
    "        for tag_label in tag_label_row:\n",
    "            if tag_label >= thresh:\n",
    "                temp.append(1) # Infer tag value as 1 (present)\n",
    "            else:\n",
    "                temp.append(0) # Infer tag value as 0 (absent)\n",
    "        y_pred.append(temp)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "scores=[] # Store the list of f1 scores for prediction on each threshold\n",
    "\n",
    "#convert labels to 1D array\n",
    "y_true = flat_true_labels.ravel() \n",
    "\n",
    "# for thresh in threshold:\n",
    "    \n",
    "#classes for each threshold\n",
    "pred_bin_label = classify(flat_pred_outs,thresh) \n",
    "\n",
    "#convert to 1D array\n",
    "y_pred = np.array(pred_bin_label).ravel()\n",
    "\n",
    "scores.append(metrics.f1_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# find the optimal threshold\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m opt_thresh \u001b[39m=\u001b[39m threshold[scores\u001b[39m.\u001b[39;49mindex(\u001b[39mmax\u001b[39;49m(scores))]\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOptimal Threshold Value = \u001b[39m\u001b[39m{\u001b[39;00mopt_thresh\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# find the optimal threshold\n",
    "opt_thresh = threshold[scores.index(max(scores))]\n",
    "print(f'Optimal Threshold Value = {opt_thresh}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Score Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for optimal threshold\n",
    "y_pred_labels = classify(flat_pred_outs,0.5)\n",
    "y_pred = np.array(y_pred_labels).ravel() # Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00  12254176\n",
      "           1       0.79      0.54      0.64     29579\n",
      "\n",
      "    accuracy                           1.00  12283755\n",
      "   macro avg       0.89      0.77      0.82  12283755\n",
      "weighted avg       1.00      1.00      1.00  12283755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f138486d0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Threshold')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1 score')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = np.arange(0.1, 1, 0.05)\n",
    "f1_scores = []\n",
    "y_true = flat_true_labels.ravel() \n",
    "for threshold in thresholds:\n",
    "    y_pred_labels = classify(flat_pred_outs, threshold)\n",
    "    y_pred = np.array(y_pred_labels).ravel() # Flatten\n",
    "    \n",
    "    f1_scores.append(metrics.classification_report(y_true, y_pred, output_dict=True)['macro avg']['f1-score'])\n",
    "\n",
    "# plot the F1 score for different thresholds\n",
    "plt.plot(thresholds, f1_scores)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlb.inverse_transform(np.array(y_pred_labels))\n",
    "y_act = mlb.inverse_transform(flat_true_labels)\n",
    "\n",
    "df = pd.DataFrame({'Body':x_test,'Actual Tags':y_act,'Predicted Tags':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Actual Tags</th>\n",
       "      <th>Predicted Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>[Commission, Regulation, EC, establish, standa...</td>\n",
       "      <td>(1118, 1605, 2635, 693)</td>\n",
       "      <td>(1118, 1605, 2511, 2635, 693)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>[Commission, Regulation, EC, fix, export, refu...</td>\n",
       "      <td>(3568, 4315, 4316)</td>\n",
       "      <td>(3568, 4315, 4316)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>[EC, Commission, Decision, January, extension,...</td>\n",
       "      <td>(1445, 1821, 4821, 5034, 5334, 893)</td>\n",
       "      <td>(4821, 5034, 893)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>[Commission, Regulation, EU, November, amend, ...</td>\n",
       "      <td>(1445, 1598, 1937, 2211, 2891, 5252, 616, 6307)</td>\n",
       "      <td>(1445, 192, 1937, 5034)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>[Commission, implement, Decision, finance, wor...</td>\n",
       "      <td>(1000, 5158, 5769, 6569)</td>\n",
       "      <td>(1005, 191, 5462, 6569)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>[Commission, Regulation, EC, February, concern...</td>\n",
       "      <td>(4163, 5451, 6052, 6322)</td>\n",
       "      <td>(1277, 1590, 6052, 6322)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>[Euratom, EEC, Commission, Decision, March, au...</td>\n",
       "      <td>(2602, 3246, 336, 5868)</td>\n",
       "      <td>(4585, 5581)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>[EEC, Commission, Decision, June, amend, Counc...</td>\n",
       "      <td>(1374, 1642, 192, 3191, 4689, 5063)</td>\n",
       "      <td>(1374, 192, 4689)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>[Commission, Regulation, EC, December, amend, ...</td>\n",
       "      <td>(1309, 2957, 3732, 4078)</td>\n",
       "      <td>(1309, 2300, 2871, 3732, 4078, 4080)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>[EC, Commission, Decision, October, draw, prov...</td>\n",
       "      <td>(1598, 1644, 2300, 2738, 3191)</td>\n",
       "      <td>(1309, 192, 2300, 2738)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Body  \\\n",
       "3374  [Commission, Regulation, EC, establish, standa...   \n",
       "4282  [Commission, Regulation, EC, fix, export, refu...   \n",
       "3522  [EC, Commission, Decision, January, extension,...   \n",
       "3651  [Commission, Regulation, EU, November, amend, ...   \n",
       "3644  [Commission, implement, Decision, finance, wor...   \n",
       "351   [Commission, Regulation, EC, February, concern...   \n",
       "4224  [Euratom, EEC, Commission, Decision, March, au...   \n",
       "3940  [EEC, Commission, Decision, June, amend, Counc...   \n",
       "921   [Commission, Regulation, EC, December, amend, ...   \n",
       "2077  [EC, Commission, Decision, October, draw, prov...   \n",
       "\n",
       "                                          Actual Tags  \\\n",
       "3374                          (1118, 1605, 2635, 693)   \n",
       "4282                               (3568, 4315, 4316)   \n",
       "3522              (1445, 1821, 4821, 5034, 5334, 893)   \n",
       "3651  (1445, 1598, 1937, 2211, 2891, 5252, 616, 6307)   \n",
       "3644                         (1000, 5158, 5769, 6569)   \n",
       "351                          (4163, 5451, 6052, 6322)   \n",
       "4224                          (2602, 3246, 336, 5868)   \n",
       "3940              (1374, 1642, 192, 3191, 4689, 5063)   \n",
       "921                          (1309, 2957, 3732, 4078)   \n",
       "2077                   (1598, 1644, 2300, 2738, 3191)   \n",
       "\n",
       "                            Predicted Tags  \n",
       "3374         (1118, 1605, 2511, 2635, 693)  \n",
       "4282                    (3568, 4315, 4316)  \n",
       "3522                     (4821, 5034, 893)  \n",
       "3651               (1445, 192, 1937, 5034)  \n",
       "3644               (1005, 191, 5462, 6569)  \n",
       "351               (1277, 1590, 6052, 6322)  \n",
       "4224                          (4585, 5581)  \n",
       "3940                     (1374, 192, 4689)  \n",
       "921   (1309, 2300, 2871, 3732, 4078, 4080)  \n",
       "2077               (1309, 192, 2300, 2738)  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e4948375748b4327b745d5a2dae00a5af67158785800fa79ee8701babd6dc22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
